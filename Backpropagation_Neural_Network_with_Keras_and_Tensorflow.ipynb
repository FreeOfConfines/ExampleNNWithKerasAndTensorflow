{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backpropagation Neural Network with Keras and Tensorflow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/FreeOfConfines/ExampleNNWithKerasAndTensorflow/blob/master/Backpropagation_Neural_Network_with_Keras_and_Tensorflow.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "LQlOYsel_v1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Build an Example Neural Network Using Keras and Tensorflow</h1>"
      ]
    },
    {
      "metadata": {
        "id": "8wRHn8JeEENK",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[Getting Started](#updateTitle=true&folderId=1PIZOzXSYokZJyrV92mRbYGRQMq-w7swD&scrollTo=W8Sda0tTBugH)\n",
        "\n",
        ">[Download Fashion MNIST Database](#updateTitle=true&folderId=1PIZOzXSYokZJyrV92mRbYGRQMq-w7swD&scrollTo=emlDOZodCJhf)\n",
        "\n",
        ">[Build Neural Network](#updateTitle=true&folderId=1PIZOzXSYokZJyrV92mRbYGRQMq-w7swD&scrollTo=kAuuIGJNQ_Fq)\n",
        "\n",
        ">[Train Neural Network](#updateTitle=true&folderId=1PIZOzXSYokZJyrV92mRbYGRQMq-w7swD&scrollTo=FfGijbkRle74)\n",
        "\n",
        ">[Classify with Neural Network](#updateTitle=true&folderId=1PIZOzXSYokZJyrV92mRbYGRQMq-w7swD&scrollTo=HVFJwUZv_5zI)\n",
        "\n",
        ">[Summary](#updateTitle=true&folderId=1PIZOzXSYokZJyrV92mRbYGRQMq-w7swD&scrollTo=nePQh4wMGPIQ)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "W8Sda0tTBugH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "The following material is a re-write / repeat of the material posted in [link text](https://www.tensorflow.org/tutorials/keras/basic_classification). I am using Google's material as a tool for learning.\n",
        "\n",
        "First step is to import libraries that are required for this exercise. Tensorflow, Keras, Numpy and Pyplot are the four we import for this exercise."
      ]
    },
    {
      "metadata": {
        "id": "9meLRiAvASM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emlDOZodCJhf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Fashion MNIST Database\n",
        "With every exercise with neural network, we need a dataset to work with. Typically, you split the dataset into two: **Train Set** and **Test Set**. Use the Train Set to train weights and biases of the neural network by presenting the network with labeled examples. Labeled examples provide the supervision required for the network to train its weights and biases. This process of training is often referred to as **Supervised Learning**. Let us download the Fashion MNIST databased for this example"
      ]
    },
    {
      "metadata": {
        "id": "Ix2MdCSEDvak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(trImages, trLabels), (tImages, tLabels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-IfI1uqI9rk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's understand the dimensions of the download dataset."
      ]
    },
    {
      "metadata": {
        "id": "CYaS6Pc-JdJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"--------------------------\")\n",
        "print(\"Dimensions of Train Set\")\n",
        "print(\"Dimension(trImages)=\",np.shape(trImages))\n",
        "print(\"There are\", np.shape(trImages)[0], \"images where each image is\", np.shape(trImages)[1:], \"in size\")\n",
        "print(\"There are\", np.shape(np.unique(tLabels))[0], \"unique image labels\")\n",
        "print(\"--------------------------\")\n",
        "print(\"Dimensions of Test Set\")\n",
        "print(\"Dimension(tImages)=\",np.shape(tImages), \"Dimension(tLabels)=\", np.shape(tLabels)[0])\n",
        "print(\"--------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R50YWPt5NY46",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us understand the images and what they look like."
      ]
    },
    {
      "metadata": {
        "id": "M-YiUObVNvdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.imshow(trImages[0]) # plotting an image\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.draw()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.imshow(trImages[1])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BOXH7YSMO6CK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that pixels of an image can take values from 0 to 255. For this exercise, we will normalize pixel values by 256, i.e., resultant values will be between (but including) 0 and 1."
      ]
    },
    {
      "metadata": {
        "id": "bqyQAyHgPmtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocess train images\n",
        "trImages = trImages/255\n",
        "tImages = tImages/255\n",
        "\n",
        "# Plot samples of prepprocessed images\n",
        "plt.figure(1)\n",
        "plt.imshow(trImages[0]) # plotting an image\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.draw()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.imshow(trImages[1])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAuuIGJNQ_Fq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build Neural Network\n",
        "\n",
        "Let us build a neural network one layer at a time. The first layer takes in images as input; we will flatten or linearize pixel values in an image and feed them to the input layer. The second layer contains 128 units and each unit will connect through an edge to every unit in the input layer. The third layer contains 10 units (one each for each unique label) and each unit in the third or output layer connects to every unit in the second layer.\n",
        "\n",
        "Typically, each unit is associated with a **Bias** value and each edge is associated with a **Weight** value. Each unit is a computation engine that aggregates messages coming in and applies a non-linear function (referred to as **activation** function)on the aggregation."
      ]
    },
    {
      "metadata": {
        "id": "DAa6LEDDTjtT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential() # Sequential model\n",
        "\n",
        "nBatchSize = 4 # play with this, you can set it to 1, 32, 64, or as big as size of train images\n",
        "layer0 = tf.keras.layers.Flatten(input_shape=np.shape(trImages[0]),batch_size=nBatchSize) # linearizing input matrix into an array\n",
        "model.add(layer0)\n",
        "\n",
        "layer1 = tf.keras.layers.Dense(units=128,activation=tf.nn.relu)\n",
        "model.add(layer1)\n",
        "\n",
        "layer2 = tf.keras.layers.Dense(units=10,activation=tf.nn.softmax)\n",
        "model.add(layer2)\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtE0ISgnFyT0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Having built and compiled the model, we will examine the various components of the model. "
      ]
    },
    {
      "metadata": {
        "id": "aZAxiB_dFhU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Layer-0:\")\n",
        "print(\"\\t\",\"Shape of images=\", layer0.input_shape, \"flattened to\", layer0.output_shape)\n",
        "print(\"\\t\"\"Number of weights+bias=\",layer0.count_params())\n",
        "print(\"\")\n",
        "print(\"Layer-1:\")\n",
        "print(\"\\t\",\"Shape of input layer=\",layer1.input_shape, \"Shape of output layer=\",layer1.output_shape)\n",
        "print(\"\\t\",\"Number of weights+bias=\",layer1.count_params())\n",
        "print(\"\")\n",
        "print(\"Layer-2:\")\n",
        "print(\"\\t\",\"Shape of input layer=\",layer2.input_shape, \"Shape of output layer=\",layer2.output_shape)\n",
        "print(\"\\t\",\"Number of weights+bias=\",layer2.count_params())\n",
        "print(\"\")\n",
        "\n",
        "print(\"Total number of parameters, i.e., weights+bias, in the model=\", model.count_params())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfGijbkRle74",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train Neural Network\n",
        "\n",
        "To train a neural network, we present images in Train Set and their corresponding labels to the network. Given the batch size is set to 4, weights and bias(es) of the network are adjusted (or adapted) after processing 4 images. This process continues until we exhaust through all 60000 images in Train Set and this constitutes an** Epoch**. Here we will run 5 epochs as seen in the code snippet below."
      ]
    },
    {
      "metadata": {
        "id": "4nFy3MNznoKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6bf7a8e5-b0f3-454a-dac0-7b9b04060f3e"
      },
      "cell_type": "code",
      "source": [
        "trHistory = model.fit(trImages,trLabels,epochs=5,batch_size=nBatchSize)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.4785 - acc: 0.8280\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.3686 - acc: 0.8665\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 0.3370 - acc: 0.8767\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.3196 - acc: 0.8825\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 0.3071 - acc: 0.8872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jueji3VmqSun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0c20e599-a613-4b90-ae31-fe471acc7162"
      },
      "cell_type": "code",
      "source": [
        "print(\"Train Parameters\")\n",
        "print(\"\\t\", trHistory.params)\n",
        "print(\"Train History\")\n",
        "print(\"\\t\", trHistory.history)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Parameters\n",
            "\t {'batch_size': 4, 'epochs': 5, 'steps': None, 'samples': 60000, 'verbose': 1, 'do_validation': False, 'metrics': ['loss', 'acc']}\n",
            "Train History\n",
            "\t {'loss': [0.47850587976766573, 0.36864339794743356, 0.33698032079253304, 0.3195559577478008, 0.3071497839308383], 'acc': [0.8279666666666666, 0.8664833333333334, 0.87675, 0.8824666666666666, 0.8872333333333333]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j2ygiYhatfcZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As part of history, we observe how Loss and Accuracy has changes across epochs. We should expect Loss to drop with every epoch and Accuracy to increase with every epoch.\n",
        "\n",
        "Below, we will review the weights and bias(es) obtained from the training. In the plot capturing Weights between Layer0-Layer1, there are 128 curves corresponding to 128 units in Layer1 and each curve contains 784 Weights. The second plot captures 128 Bias values corresponding to 128 units in Layer1 (or the second layer)."
      ]
    },
    {
      "metadata": {
        "id": "lQMl_vJfxAPf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot trained weights and bias(es)\n",
        "plt.figure()\n",
        "plt.plot(layer1.get_weights()[0])\n",
        "plt.title(\"Weights Layer0-Layer1\")\n",
        "plt.legend(['Hello'])\n",
        "plt.draw()\n",
        "plt.figure()\n",
        "plt.plot(layer1.get_weights()[1])\n",
        "plt.title(\"Bias Layer1\")\n",
        "plt.draw()\n",
        "plt.figure()\n",
        "plt.plot(layer2.get_weights()[0])\n",
        "plt.title(\"Weights Layer1-Layer2\")\n",
        "plt.draw()\n",
        "plt.figure()\n",
        "plt.plot(layer2.get_weights()[1])\n",
        "plt.title(\"Bias Layer2\")\n",
        "plt.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HVFJwUZv_5zI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Classify with Neural Network\n",
        "\n",
        "Having trained weights and bias(es) of the network, use them to classify Test images into one of 10 categories. By running the code below you will find that the neural network is able to classify images in Test set with an accuracy of 87.2%. For each image presented to the network, output of the 10 units is recorded as rows of the `predictions` array."
      ]
    },
    {
      "metadata": {
        "id": "_mswttnu_Nli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2e4be49-b229-466c-d1f2-11bf2607a42d"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(tImages,batch_size=nBatchSize,verbose=1) # predictions is a matrix of 10000 x 10, where 10 is the size of the output layer\n",
        "nCorrect = 0\n",
        "for i in range(np.shape(predictions)[0]): # process one row at a time\n",
        "  predictedIndex = predictions[i].argmax()\n",
        "  trueIndex = tLabels[i]\n",
        "  nCorrect = nCorrect + (trueIndex==predictedIndex)\n",
        "print(\"# Correct Predictions=\", nCorrect, \"% Correct=\", 100*nCorrect/np.shape(predictions)[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 106us/step\n",
            "# Correct Predictions= 8720 % Correct= 87.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nePQh4wMGPIQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Keras and Tensorflow has made it simple to set up, train, and predict with a neural network. In addition, we have explored ways to extract, examine, and analyze various aspects of the network."
      ]
    }
  ]
}